# ğŸ« Lung Tumor Detection using NSCLC-Radiomics Dataset

A comprehensive approach for automated lung tumor detection in Non-Small Cell Lung Cancer (NSCLC) patients using deep learning and medical imaging.

## ğŸ“‹ Table of Contents
- [Overview](#overview)
- [Dataset](#dataset)
- [Data Pipeline](#data-pipeline)
- [Preprocessing](#preprocessing)
- [Bounding Box Generation](#bounding-box-generation)
- [Model Training](#model-training)
- [Evaluation](#evaluation)
- [Results](#results)


## ğŸ¯ Overview

This repository contains our implementation for automated lung tumor detection using the NSCLC-Radiomics dataset. Our approach leverages 3D deep learning models to identify and localize tumors in CT scans from Non-Small Cell Lung Cancer patients across different stages.

## ğŸ“Š Dataset

**Source**: [NSCLC-Radiomics Dataset](https://www.cancerimagingarchive.net/collection/nsclc-radiomics/) from The Cancer Imaging Archive

**Specifications**:
- ğŸ“ **Total Patients**: 420 CT scans with segmentation maps
- ğŸ¥ **Patient Population**: Non-Small Cell Lung Cancer patients (various stages)
- ğŸ’¾ **Format**: DICOM files with corresponding segmentation masks

**Data Split**:
- ğŸ§ª **Test Set**: 42 patients (10% held out for final evaluation)
- ğŸ”„ **Training/Validation**: 378 patients (90% with 10-fold cross-validation)

## ğŸ”„ Data Pipeline

### 1. Format Conversion (DICOM â†’ NRRD)

We utilize **Plastimatch** for efficient DICOM to NRRD conversion:

#### CT Scan Conversion:
```bash
plastimatch convert --input DCM_FOLDER --output-img CT.nrrd
```

#### Mask Conversion:
```bash
plastimatch convert \
  --input 3.000000-78236/1-1.dcm \
  --interpolation=nn \
  --output-type=uchar \
  --referenced-ct 0.000000-82046 \
  --output-prefix segmentations \
  --prefix-format nrrd \
  --fixed
```

## ğŸ”§ Preprocessing

### Image Standardization
- **ğŸ“ Resampling**: Standardized to 1.0 Ã— 1.0 Ã— 3.0 mm (x, y, z) resolution
- **ğŸšï¸ Intensity Clipping**: Values clipped between -1000 and 500 HU
- **ğŸ“Š Normalization**: Mean = 0, Standard deviation = 1

### Training Configuration
- **ğŸ“¦ Patch Size**: [144, 144, 33] (x, y, z)
- **ğŸ”„ Inference Method**: Sliding window approach for full volume coverage
- **ğŸƒ Training Duration**: 300 epochs with identical hyperparameters
- **ğŸ¯ Model Selection**: Based on lowest validation loss

## ğŸ“¦ Bounding Box Generation

Since the dataset lacks bounding box annotations, we extract them from segmentation masks using **SimpleITK**:

### Process Workflow:
1. **ğŸ“¥ Load Images**: Load CT scans and corresponding mask images
2. **ğŸ” Component Analysis**: Identify connected components in segmentation mask
3. **ğŸ·ï¸ Label Assignment**: Assign unique labels to each connected region
4. **ğŸ“Š Property Computation**: Calculate properties for each connected component
5. **ğŸ“ Coordinate Extraction**: Extract bounding box coordinates
6. **ğŸ“‹ Format Conversion**: Convert to standardized format
   
<img width="769" height="706" alt="BBox" src="https://github.com/user-attachments/assets/f50dda5b-dbd7-4d5b-b898-16f37fd2fc79" />

### Output Formats:
- **Voxel Coordinates**: `[x_min, y_min, z_min, x_size, y_size, z_size]`
- **Physical Coordinates**: `[x_center, y_center, z_center, x_size_physical, y_size_physical, z_size_physical]`

## ğŸ¤– Model Training

### Framework
We leverage the **MONAI Detection** framework for robust medical image analysis:
- **Repository**: [MONAI Detection Tutorials](https://github.com/Project-MONAI/tutorials/tree/main/detection)
- **Architecture**: 3D detection model optimized for medical imaging
- **Training Strategy**: 10-fold cross-validation on 90% of data

## ğŸ“ˆ Evaluation

### Primary Metrics
- **ğŸ“Š Mean Average Precision (mAP)**: Across different cross-validation folds
- **ğŸ¯ Mean Average Recall (mAR)**: Comprehensive detection performance assessment

### Detailed Analysis
- **ğŸ“‹ Case-by-case IoU**: Individual patient evaluation on 42-patient test set
- **ğŸ“ˆ Correlation Analysis**: Pearson correlation between IoU and:
  - Tumor size
  - Tumor location

## ğŸ‰ Results

### Key Findings
- **âœ… Unbiased Detection**: No strong correlation found between model performance and tumor characteristics
- **ğŸ“ Size Independence**: Model performs consistently across different tumor sizes
- **ğŸ“ Location Independence**: Performance not biased by tumor location
- **ğŸ¯ Robust Performance**: Consistent detection across various patient cases

### Statistical Analysis
The Pearson correlation analysis revealed **no significant bias** in the model's identification capabilities, indicating robust generalization across diverse tumor presentations.



## ğŸ“š References

- **Dataset**: Aerts, H. J. W. L., et al. "Data From NSCLC-Radiomics." The Cancer Imaging Archive (2019).
- **Framework**: MONAI Detection - PyTorch-based framework for medical imaging AI
- **Tools**: Plastimatch for medical image processing

**Note**: This project demonstrates the application of deep learning techniques for automated medical image analysis, specifically targeting lung tumor detection in clinical CT scans.
